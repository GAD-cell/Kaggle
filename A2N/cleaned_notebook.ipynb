{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data (complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2615, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"./data/mars_for_students.npz\")\n",
    "training_set = data[\"training_set\"]\n",
    "\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "X_test = data[\"test_set\"]\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.conv(x)\n",
    "        p = self.pool(s)\n",
    "        return s, p\n",
    "\n",
    "class attention_gate(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Wg = nn.Sequential(\n",
    "            nn.Conv2d(in_c[0], out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        self.Ws = nn.Sequential(\n",
    "            nn.Conv2d(in_c[1], out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, g, s):\n",
    "        Wg = self.Wg(g)\n",
    "        Ws = self.Ws(s)\n",
    "        out = self.relu(Wg + Ws)\n",
    "        out = self.output(out)\n",
    "        return out * s\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.ag = attention_gate(in_c, out_c)\n",
    "        self.c1 = conv_block(in_c[0]+out_c, out_c)\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        x = self.up(x)\n",
    "        s = self.ag(x, s)\n",
    "        x = torch.cat([x, s], axis=1)\n",
    "        x = self.c1(x)\n",
    "        return x\n",
    "\n",
    "class attention_unet(nn.Module):\n",
    "    def __init__(self,in_channels=1,out_channels=5,deep_sup=True):\n",
    "        super().__init__()\n",
    "        self.deep_sup=deep_sup\n",
    "\n",
    "        self.e1 = encoder_block(in_channels, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        self.b1 = conv_block(512, 1024)\n",
    "        \n",
    "        self.d4 = decoder_block([1024, 512], 512)\n",
    "        self.d3 = decoder_block([512, 256], 256)\n",
    "        self.d2 = decoder_block([256, 128], 128)\n",
    "        self.d1 = decoder_block([128, 64], 64)\n",
    "\n",
    "        self.output = nn.Conv2d(64, out_channels, kernel_size=1, padding=0)\n",
    "        self.o_d2=nn.Conv2d(128, out_channels, kernel_size=1, padding=0)\n",
    "        self.o_d3=nn.Conv2d(256, out_channels, kernel_size=1, padding=0)\n",
    "        self.o_d4=nn.Conv2d(512, out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1, p1 = self.e1(x)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "        \n",
    "        b1 = self.b1(p4)\n",
    "        \n",
    "        d4 = self.d4(b1, s4)\n",
    "        d3 = self.d3(d4, s3)\n",
    "        d2 = self.d2(d3, s2)\n",
    "        d1 = self.d1(d2, s1)\n",
    "\n",
    "\n",
    "        if self.deep_sup:\n",
    "            d2=F.interpolate(self.o_d2(d2),scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
    "            d3=F.interpolate(self.o_d3(d3),scale_factor=4,mode=\"bilinear\",align_corners=True)\n",
    "            d4=F.interpolate(self.o_d4(d4),scale_factor=8,mode=\"bilinear\",align_corners=True)\n",
    "            output = self.output(d1)\n",
    "            return output,d2,d3,d4\n",
    "        else : \n",
    "            output = self.output(d1)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, large_kernels=False):\n",
    "        super(UNet, self).__init__()\n",
    "        kernel_size = 5 if large_kernels else 3\n",
    "        padding = 2 if large_kernels else 1\n",
    "\n",
    "        self.encoder1 = DoubleConv(in_channels, 64, kernel_size, padding)\n",
    "        self.encoder2 = DoubleConv(64, 128, kernel_size, padding)\n",
    "        self.encoder3 = DoubleConv(128, 256, kernel_size, padding)\n",
    "        self.encoder4 = DoubleConv(256, 512, kernel_size, padding)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = DoubleConv(512, 1024, kernel_size, padding)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.decoder4 = DoubleConv(1024, 512, kernel_size, padding)\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.decoder3 = DoubleConv(512, 256, kernel_size, padding)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.decoder2 = DoubleConv(256, 128, kernel_size, padding)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.decoder1 = DoubleConv(128, 64, kernel_size, padding)\n",
    "\n",
    "        self.output_layer = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Auxiliary outputs for deep supervision\n",
    "        self.aux_output4 = nn.Conv2d(512, out_channels, kernel_size=1)\n",
    "        self.aux_output3 = nn.Conv2d(256, out_channels, kernel_size=1)\n",
    "        self.aux_output2 = nn.Conv2d(128, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Upsampling layers for resizing auxiliary outputs\n",
    "        self.upsample4 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = torch.cat((d4, e4), dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "        aux4 = self.upsample4(self.aux_output4(d4))  # Resize auxiliary output\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat((d3, e3), dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "        aux3 = self.upsample3(self.aux_output3(d3))  # Resize auxiliary output\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((d2, e2), dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "        aux2 = self.upsample2(self.aux_output2(d2))  # Resize auxiliary output\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((d1, e1), dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        final_output = self.output_layer(d1)\n",
    "\n",
    "        return final_output, aux4, aux3, aux2\n",
    "\n",
    "class DoubleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleUNet, self).__init__()\n",
    "        self.unet1 = UNet(in_channels, out_channels, large_kernels=True)\n",
    "        self.unet2 = UNet(out_channels + in_channels, out_channels, large_kernels=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the first UNet\n",
    "        out1, aux4_1, aux3_1, aux2_1 = self.unet1(x)\n",
    "        normalized_out1 = (out1 - out1.mean(dim=(2, 3), keepdim=True)) / (out1.std(dim=(2, 3), keepdim=True) + 1e-8)\n",
    "        combined_input = torch.cat((x, normalized_out1), dim=1)\n",
    "\n",
    "        # Forward pass through the second UNet\n",
    "        out2, aux4_2, aux3_2, aux2_2 = self.unet2(combined_input)\n",
    "\n",
    "        return out2,aux2_1,aux4_2, aux3_2, aux2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.softmax(preds, dim=1) \n",
    "        num_classes = preds.shape[1]\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        dice_loss = 0.0\n",
    "        for c in range(num_classes):\n",
    "\n",
    "            pred_c = preds[:, c, :, :]\n",
    "            target_c = targets_one_hot[:, c, :, :]\n",
    "\n",
    "            # IoU\n",
    "            intersection = torch.sum(pred_c * target_c, dim=(1, 2))  \n",
    "            union = torch.sum(pred_c + target_c, dim=(1, 2)) \n",
    "\n",
    "            dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "            dice_loss += (1 - dice).mean()  # Mean on the batch\n",
    "\n",
    "        # mean on the classes\n",
    "        return dice_loss / num_classes\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction  # 'mean', 'sum' or 'none'\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = torch.softmax(inputs, dim=1)  # Softmax\n",
    "        targets = targets.long()\n",
    "\n",
    "        N, C, H, W = inputs.size()\n",
    "        inputs = inputs.view(N, C, -1)  # (batch_size, num_classes, height * width)\n",
    "        targets = targets.view(N, -1)   # (batch_size, height * width)\n",
    "\n",
    "        one_hot = torch.zeros(N, C, H * W).to(inputs.device)\n",
    "        one_hot.scatter_(1, targets.unsqueeze(1), 1)  # Good shape\n",
    "\n",
    "        p_t = (inputs * one_hot).sum(dim=1)  # Probability target predictions\n",
    "        loss = -self.alpha * (1 - p_t) ** self.gamma * torch.log(p_t + 1e-8)\n",
    "\n",
    "        # reduction\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.focal_loss = FocalLoss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        dice = self.dice_loss(preds, targets)\n",
    "        focal = self.focal_loss(preds, targets)\n",
    "        return 0.5 * dice + 0.5 * focal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,random_split\n",
    "import numpy as np\n",
    "from CpNet import CPNet \n",
    "from attunet import attention_unet\n",
    "import torchmetrics\n",
    "import metrics\n",
    "from u2net import U2NET\n",
    "\n",
    "# Hyperparameter\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "num_classes = 5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "print(X_train_tensor.shape,y_train_tensor.shape)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor.to(device), y_train_tensor.to(device))\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.95, 0.05])\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "#model=attention_unet(in_channels=1)\n",
    "model=DoubleUNet(in_channels=1,out_channels=5)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = CombinedLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=5).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output_and_label(output, label):\n",
    "\n",
    "    output = output.squeeze(0).detach().cpu().numpy()  \n",
    "    label = label.squeeze(0).detach().cpu().numpy() \n",
    "\n",
    "\n",
    "    output_class = np.argmax(output, axis=0)\n",
    "\n",
    " \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "\n",
    "    ax[0].imshow(output_class, cmap='jet') \n",
    "    ax[0].set_title('Output (Predicted Classes)')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(label, cmap='jet') \n",
    "    ax[1].set_title('Label (Ground Truth)')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics.classification import JaccardIndex\n",
    "import albumentations as A\n",
    "\n",
    "# Configuration\n",
    "train_val_split_ratio = 0.95 \n",
    "patience = 10\n",
    "min_delta = 0.001  \n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "\n",
    "# Optimizer et Scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "\n",
    "\n",
    "def deep_supervision_loss(outputs, labels, criterion, weights=None):\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(outputs)] * len(outputs)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    for i, output in enumerate(outputs):\n",
    "        total_loss += weights[i] * criterion(output, labels)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_miou = 0.0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Loss calculation\n",
    "        loss=deep_supervision_loss(outputs,labels,criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_miou += jaccard(outputs[0], labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_miou = running_miou / len(train_loader)\n",
    "\n",
    "    # Visualisation\n",
    "    if epoch % 10 == 0:\n",
    "        plot_output_and_label(outputs[0][0], labels[0])\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_miou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.squeeze(1)\n",
    "            loss = deep_supervision_loss(outputs,labels,criterion)\n",
    "            val_loss += loss.item()\n",
    "            val_miou += jaccard(outputs[0], labels)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_miou /= len(val_loader)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"Arrêt anticipé à l'époque {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "    \n",
    "    lr_scheduler.step(val_loss)\n",
    "\n",
    "    # metrics\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, mIoU: {epoch_miou:.4f}, -Val_Loss: {val_loss:.4f}, Val_mIoU: {val_miou:.4f} Lr: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "test_dataset = TensorDataset(X_test_tensor.to(device))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "all_preds=[]\n",
    "with torch.no_grad():\n",
    "    for batch  in test_loader:\n",
    "        preds = model(batch[0])\n",
    "        all_preds.append(preds[0].cpu().numpy())\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_preds = np.argmax(all_preds, axis=1)\n",
    "print(f\"Predictions shape: {all_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "def y_to_df(y) -> pd.DataFrame:\n",
    "    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n",
    "    n_samples = len(y)\n",
    "    y_flat = y.reshape(n_samples, -1)\n",
    "    df = pd.DataFrame(y_flat)\n",
    "    df[\"id\"] = np.arange(n_samples)\n",
    "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "    return df[cols]\n",
    "\n",
    "# Create and download the csv submission file\n",
    "submission_filename = f\"./submission/submission_dp1.csv\"\n",
    "submission_df = y_to_df(all_preds)\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
