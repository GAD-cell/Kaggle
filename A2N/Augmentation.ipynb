{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BBfccWx5z3SsSvUUCNMXWuuJKiapZYjA","timestamp":1733770111246}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Artificial Neural Networks and Deep Learning\n","\n","---\n","\n","## Homework 2: Exploring Augmentations\n","\n","‚ùóThis notebook is using a presumably over-cleaned dataset. However, despite this inconvenience, it should still be useful enough to experiment with different augmentation approaches.  \n"],"metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":["## üåê Connect Colab to Google Drive"],"metadata":{"id":"dw_-hFm6bjY6"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount(\"/gdrive\")\n","%cd /gdrive/My Drive/Homework_2/Data"],"metadata":{"id":"y2S4GWr3Uoa8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733817246678,"user_tz":-60,"elapsed":1962,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"afb3c569-f721-41e2-f5a8-6538f978df0d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/My Drive/Homework_2/Data\n"]}]},{"cell_type":"markdown","source":["## ‚öôÔ∏è Install Albumations and Import Libraries"],"metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":["!pip install -U git+https://github.com/albu/albumentations > /dev/null && echo \"All libraries are successfully installed!\"\n"],"metadata":{"id":"TlX0iy4r0Am6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733817264555,"user_tz":-60,"elapsed":16286,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"f494fc66-3c43-40ef-ddba-3bc1f0c84553"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["  Running command git clone --filter=blob:none --quiet https://github.com/albu/albumentations /tmp/pip-req-build-0lxje9f5\n","All libraries are successfully installed!\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"CO6_Ft_8T56A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733817279074,"user_tz":-60,"elapsed":12478,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"b09b6ef9-f421-405b-8ce6-37ddca739fde"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.17.1\n","Keras version: 3.5.0\n","GPU devices: 0\n"]}],"source":["import os\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","import matplotlib.pyplot as plt\n","\n","\n","import albumentations as A\n","from albumentations import (\n","    HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast,\n","    ShiftScaleRotate, ElasticTransform, GridDistortion, Blur, CLAHE,\n","    RandomGamma, Perspective, OneOf, Compose, Normalize\n",")\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"Keras version: {tfk.__version__}\")\n","print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"]},{"cell_type":"markdown","source":["## ‚è≥ Load the Data"],"metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":["data = np.load(\"mars_for_students.npz\")\n","\n","training_set = data[\"training_set\"]\n","X_train = training_set[:, 0]\n","y_train = training_set[:, 1]\n","\n","X_test = data[\"test_set\"]\n","\n","print(f\"Training X shape: {X_train.shape}\")\n","print(f\"Training y shape: {y_train.shape}\")\n","print(f\"Test X shape: {X_test.shape}\")"],"metadata":{"id":"pLaoDaG1V1Yg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733817289771,"user_tz":-60,"elapsed":8400,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"8222cc5b-e81b-4dec-ed00-0142dfa36568"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X shape: (2615, 64, 128)\n","Training y shape: (2615, 64, 128)\n","Test X shape: (10022, 64, 128)\n"]}]},{"cell_type":"markdown","source":["## üõ†Ô∏è Train and Save the Model"],"metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":["# Add color channel and rescale pixels between 0 and 1\n","X_train = X_train[..., np.newaxis] / 255.0\n","X_test = X_test[..., np.newaxis] / 255.0\n","\n","input_shape = X_train.shape[1:]\n","num_classes = len(np.unique(y_train))\n","\n","print(f\"Input shape: {input_shape}\")\n","print(f\"Number of classes: {num_classes}\")"],"metadata":{"id":"VmnTgJi_OOs1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733817301326,"user_tz":-60,"elapsed":2691,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"75d17a02-1538-4733-f719-9f8bf725b82a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: (64, 128, 1)\n","Number of classes: 5\n"]}]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"KkQaKNKY33D_"}},{"cell_type":"code","source":["\n","x_train_cleaned = np.load(\"x_train_cleaned.npy\")\n","y_train_cleaned = np.load(\"y_train_cleaned.npy\")\n","\n","X_train_augmented = np.load(\"X_train_augmented.npy\")\n","y_train_augmented = np.load(\"y_train_augmented.npy\")\n","\n","x_val = np.load(\"x_val.npy\")\n","y_val = np.load(\"y_val.npy\")"],"metadata":{"id":"xBAjKtEc32N8","executionInfo":{"status":"ok","timestamp":1733817495436,"user_tz":-60,"elapsed":3400,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Definition of some helper functions to extract subsets from the training data\n","- they are basically the same functions used in the process of deconstructing the original train set to build up a cleaned version, just used the other way around in this context"],"metadata":{"id":"nwlcRfxFb7pk"}},{"cell_type":"code","source":["import numpy as np\n","\n","def get_indices_with_label_range(y_train, min_labels, max_labels):\n","    indices = []\n","    for idx, mask in enumerate(y_train):\n","        unique_labels = np.unique(mask)\n","        num_labels = len(unique_labels)\n","        if min_labels <= num_labels <= max_labels:\n","            indices.append(idx)\n","    return indices\n","\n","# How to use\n","# y_train: List or array of masks\n","# min_labels: Minimum number of labels\n","# max_labels: Maximum number of labels\n","# indices = get_indices_with_label_range(y_train, min_labels=2, max_labels=5)\n","\n","# print(f\"Number of images with label counts in range [2, 5]: len({indices})\")\n","\n","import numpy as np\n","\n","def get_indices_with_specific_label(y_train, target_label):\n","    \"\"\"\n","    Returns indices of masks in y_train where the specified label is present.\n","\n","    Parameters:\n","    - y_train: Array-like, list or numpy array of masks.\n","    - target_label: The label to search for in the masks.\n","\n","    Returns:\n","    - List of indices where the target label is present.\n","    \"\"\"\n","    indices = []\n","    for idx, mask in enumerate(y_train):\n","        if target_label in np.unique(mask):\n","            indices.append(idx)\n","    return indices\n","\n","# How to use\n","# y_train: List or array of masks\n","# target_label: Label to search for\n","# indices = get_indices_with_specific_label(y_train, target_label=3)\n","\n","# print(f\"Number of images where label 3 is present: len({indices})\")\n","\n","\n","from matplotlib.colors import ListedColormap\n","\n","# Define colors for each label\n","colors = [\n","    (0, 0, 0),        # 0: Background - Black\n","    (0.5, 0.25, 0),   # 1: Soil - Brown\n","    (0.5, 0.5, 0.5),  # 2: Bedrock - Gray\n","    (1, 1, 0),        # 3: Sand - Yellow\n","    (0, 0, 1)         # 4: Big Rock - Blue\n","]\n","\n","custom_cmap = ListedColormap(colors)\n","\n","\n","def save_image_mask_pairs(train_images, train_masks, folder_name=\"train_images_with_masks\"):\n","    \"\"\"\n","    Saves image-mask pairs into a specified folder, with filenames based on their index.\n","\n","    Args:\n","        train_images (numpy.ndarray): Array of training images (shape: [N, H, W, C] or [N, H, W]).\n","        train_masks (numpy.ndarray): Array of corresponding masks (shape: [N, H, W]).\n","        folder_name (str): Name of the folder where images will be saved.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Ensure the folder exists\n","    if not os.path.exists(folder_name):\n","        os.makedirs(folder_name)\n","\n","    # Loop through the dataset\n","    for idx, (image, mask) in enumerate(zip(train_images, train_masks)):\n","        plt.figure(figsize=(10, 5))\n","\n","        # Plot the image\n","        plt.subplot(1, 2, 1)\n","        if image.ndim == 3 and image.shape[-1] == 1:  # Grayscale with channel\n","            plt.imshow(image.squeeze(), cmap=\"gray\")\n","        else:  # RGB or 2D grayscale\n","            plt.imshow(image, cmap=\"gray\")\n","        plt.title(\"Image\")\n","        plt.axis(\"off\")\n","\n","        # Plot the mask\n","        plt.subplot(1, 2, 2)\n","        plt.imshow(mask, cmap=custom_cmap, vmin=0, vmax=4)\n","        plt.title(\"Mask\")\n","        plt.axis(\"off\")\n","\n","        # Save the figure\n","        file_path = os.path.join(folder_name, f\"{idx}.png\")\n","        plt.savefig(file_path, bbox_inches=\"tight\")\n","        plt.close()\n","\n","    print(f\"Saved {len(train_images)} image-mask pairs to the folder: '{folder_name}'\")\n"],"metadata":{"id":"4F0F5S4zb5yu","executionInfo":{"status":"ok","timestamp":1733818561177,"user_tz":-60,"elapsed":301,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Extract meaningful subsets with the purpose of tailored augmentation\n"],"metadata":{"id":"X5O_1MKFdUGK"}},{"cell_type":"code","source":["print(f\"Total number of images, so far: {len(y_train_cleaned)}\")\n","\n","print(\"And from those we have:\")\n","\n","indices_containing_min_4_labels = get_indices_with_label_range(y_train_cleaned, min_labels=4, max_labels=5)\n","print(f\"Number of images with label counts in range [4, 5]: {len(indices_containing_min_4_labels)}\")\n","\n","y_train_cleaned_min_4_labels, x_train_cleaned_min_4_labels = y_train_cleaned[indices_containing_min_4_labels], x_train_cleaned[indices_containing_min_4_labels]\n","\n","indices_containing_3_labels = get_indices_with_label_range(y_train_cleaned, min_labels=3, max_labels=3)\n","print(f\"Number of images with label counts in range [3, 3]: {len(indices_containing_3_labels)}\")\n","\n","y_train_cleaned_3_labels, x_train_cleaned_3_labels = y_train_cleaned[indices_containing_3_labels], x_train_cleaned[indices_containing_3_labels]\n","\n","indices_containing_max_2_labels = get_indices_with_label_range(y_train_cleaned, min_labels=1, max_labels=2)\n","print(f\"Number of images with label counts in range [1, 2]: {len(indices_containing_max_2_labels)}\")\n","\n","y_train_cleaned_max_2_labels, x_train_cleaned_max_2_labels = y_train_cleaned[indices_containing_max_2_labels], x_train_cleaned[indices_containing_max_2_labels]\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZk5e9lQdjYw","executionInfo":{"status":"ok","timestamp":1733819986913,"user_tz":-60,"elapsed":1648,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"8f851250-f63f-425d-cd49-67df2c443dd8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of images, so far: 1074\n","And from those we have:\n","Number of images with label counts in range [4, 5]: 150\n","Number of images with label counts in range [3, 3]: 527\n","Number of images with label counts in range [1, 2]: 397\n","Number of images with big rock in the original training set:  63\n","Number of images with big rock in the cleaned training set:  63\n","Number of images with big rock in the subset with min 4 lables:  44\n","Number of images with big rock in the subset with min 4 lables:  19\n"]}]},{"cell_type":"markdown","source":["### ‚Åâ Now where are all the images of big rock ‚Åâ"],"metadata":{"id":"VRM3HMnhw0I-"}},{"cell_type":"code","source":["print(\"Number of images with big rock in the original training set: \", len(get_indices_with_specific_label(y_train, target_label=4)))\n","print(\"Number of images with big rock in the cleaned training set: \", len(get_indices_with_specific_label(y_train_cleaned, target_label=4)))\n","print(\"Number of images with big rock in the subset with min 4 labels: \",len(get_indices_with_specific_label(y_train_cleaned_min_4_labels, target_label=4)))\n","print(\"Number of images with big rock in the subset with 3 labels: \",len(get_indices_with_specific_label(y_train_cleaned_3_labels, target_label=4)))"],"metadata":{"id":"kS0BbCDBuixX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["split bed rock images and masks"],"metadata":{"id":"soNOYd95cKHM"}},{"cell_type":"code","source":["bed_rock_indices_within_min_4_labels = get_indices_with_specific_label(y_train_cleaned_min_4_labels, target_label=4)\n","bed_rock_indices_within_3_labels = get_indices_with_specific_label(y_train_cleaned_3_labels, target_label=4)\n","\n","x_bed_rock, y_bed_rock = np.concatenate((x_train_cleaned_min_4_labels[bed_rock_indices_within_min_4_labels], x_train_cleaned_3_labels[bed_rock_indices_within_3_labels])), np.concatenate((y_train_cleaned_min_4_labels[bed_rock_indices_within_min_4_labels], y_train_cleaned_3_labels[bed_rock_indices_within_3_labels]))\n","\n","x_train_cleaned_min_4_labels_without_bed_rock, y_train_cleaned_min_4_labels_without_bed_rock = np.delete(x_train_cleaned_min_4_labels, bed_rock_indices_within_min_4_labels, axis=0), np.delete(y_train_cleaned_min_4_labels, bed_rock_indices_within_min_4_labels, axis=0)\n","x_train_cleaned_3_labels_without_bed_rock, y_train_cleaned_3_labels_without_bed_rock = np.delete(x_train_cleaned_3_labels, bed_rock_indices_within_3_labels, axis=0), np.delete(y_train_cleaned_3_labels, bed_rock_indices_within_3_labels, axis=0)\n","\n","# verify\n","print(len(x_train_cleaned_min_4_labels_without_bed_rock), len(y_train_cleaned_min_4_labels_without_bed_rock)) # should be 106\n","print(len(x_train_cleaned_3_labels_without_bed_rock), len(y_train_cleaned_3_labels_without_bed_rock)) # should be 508"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rflQINdJcKjc","executionInfo":{"status":"ok","timestamp":1733833318950,"user_tz":-60,"elapsed":467,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"1665985c-d11f-41a7-f84c-bef65d5774ef"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["106 106\n","508 508\n"]}]},{"cell_type":"markdown","source":["### ‚ùá Optionally plot subsets to a folder for inspection\n","\n","- as you may have noticed, i included a function `save_image_mask_pairs(train_images, train_masks, folder_name=\"train_images_with_masks\")`\n","- we can use it to select more valuable images for augmentation, alternatively we could determine bed_rock images where the bedrock mask is above a certain threshhold, but in that case manual inspection might be more efficient"],"metadata":{"id":"zK98bDYUfpIx"}},{"cell_type":"code","source":["save_image_mask_pairs(x_bed_rock, y_bed_rock, folder_name=\"bed_rock_images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9ZCtg5VgucJ","executionInfo":{"status":"ok","timestamp":1733833344303,"user_tz":-60,"elapsed":16888,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"8dbd072b-edf5-4a63-face-278939b521bb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved 63 image-mask pairs to the folder: 'bed_rock_images'\n"]}]},{"cell_type":"code","source":["# just a small temporary selection, we could try on a simple unet first what works best for feature extraction\n","\n","some_ok_bedrock_imgs= [0, 3, 5, 6, 8, 9,57,59,60]\n","x_bed_rock_selection = x_bed_rock[some_ok_bedrock_imgs]\n","y_bed_rock_selection = y_bed_rock[some_ok_bedrock_imgs]"],"metadata":{"id":"hP_E-ILViuQ2","executionInfo":{"status":"ok","timestamp":1733834596828,"user_tz":-60,"elapsed":322,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Augmentation\n","\n"," 1. Define Augmentation Pipelines for Upsampling\n"," 2. Define `DataGenerator`\n"," 3. Visualize Augmentation Techniques\n"," 4. Upsample using Augmentations"],"metadata":{"id":"qjkxSHUNOUJ1"}},{"cell_type":"code","source":["### Pipelines"],"metadata":{"id":"VOm3vH4tO7R9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AugmentationLogger:\n","    def __init__(self, pipeline):\n","        self.pipeline = pipeline\n","        self.applied_augmentations = []\n","\n","    def __call__(self, **kwargs):\n","        # Reset log for the new call\n","        self.applied_augmentations = []\n","        augmented = self.pipeline(**kwargs)\n","\n","        # Check which augmentations were applied\n","        for transform in self.pipeline.transforms:\n","            if isinstance(transform, A.NoOp):  # Skip logging NoOp\n","                continue\n","            if isinstance(transform, A.OneOf):\n","                # For OneOf, check which transformation was applied\n","                chosen_transform = self._log_oneof(transform)\n","                if chosen_transform:\n","                    self.applied_augmentations.append(f\"OneOf({chosen_transform})\")\n","            else:\n","                if np.random.rand() < transform.p:\n","                    self.applied_augmentations.append(transform.__class__.__name__)\n","\n","        return augmented\n","\n","    def _log_oneof(self, oneof_transform):\n","        # Simulate which transformation was chosen in OneOf\n","        probs = [t.p for t in oneof_transform.transforms]\n","        total_prob = sum(probs)\n","        chosen = np.random.choice(\n","            oneof_transform.transforms,\n","            p=[p / total_prob for p in probs]\n","        )\n","        return chosen.__class__.__name__\n","\n","    def get_log(self):\n","        return self.applied_augmentations\n"],"metadata":{"id":"qVoXRp1O3Cjg","executionInfo":{"status":"ok","timestamp":1733839365952,"user_tz":-60,"elapsed":364,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","def get_3_classes_augmentation_pipeline():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.3),  # for non class 4 probably not a bad idea\n","\n","        # Light geometric Variationen\n","        A.OneOf([\n","            A.Rotate(limit=10, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n","            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10,\n","                               border_mode=cv2.BORDER_REFLECT_101, p=0.5), # this can be useful if we aim smooth out the effects of geometric artifacts\n","        ], p=0.3),\n","\n","        # Light Simulation of different perspectives\n","        A.OneOf([\n","            A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.4),\n","            A.Perspective(scale=(0.02, 0.05), keep_size=True, p=0.2),\n","            A.NoOp()\n","        ], p=0.5),\n","\n","\n","        A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.18, p=0.5),\n","\n","\n","        A.RandomGamma(gamma_limit=(80,120), p=0.3),\n","\n","        A.OneOf([\n","            A.Blur(blur_limit=3, p=0.3),\n","            A.Sharpen(alpha=(0.2, 0.4), lightness=(0.8,1.0), p=0.3),\n","            A.NoOp()\n","        ], p=0.4),\n","\n","    ], additional_targets={'mask': 'mask'})\n","\n","\n","def get_bedrock_augmentation_pipeline():\n","    return A.Compose([\n","        # A.VerticalFlip is probably confusing on big rock\n","        A.HorizontalFlip(p=0.5),\n","\n","\n","       # this can be used with caution if we observe the model lacks in robustness to handle orientation by implementing a bounding-box-based conditional strategy, meaning using it iff big rock isnt on the border, s.t. we dont cut it off,\n","\n","        #A.OneOf([\n","            #A.Rotate(limit=10, border_mode=0, p=0.7),\n","            #A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, border_mode=0, p=0.5), A.NoOp()], p=0.5),\n","\n","        A.OneOf([\n","            #A.GridDistortion(num_steps=5, distort_limit=0.1, p=0.2), # potentially hiding big rock, so not a good idea\n","            A.Perspective(scale=(0.02, 0.05), keep_size=True, p=0.2),\n","            A.NoOp()\n","        ], p=0.5),\n","\n","\n","        A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.1, p=0.5),\n","\n","        A.RandomGamma(gamma_limit=(90,110), p=0.3), # Weniger Variation als bei non class4\n","\n","        # less blur more sharpen\n","        A.OneOf([\n","            A.Sharpen(alpha=(0.2, 0.5), lightness=(0.8,1.0), p=0.5),\n","            A.Blur(blur_limit=2, p=0.2),\n","            A.NoOp()\n","        ], p=0.5),\n","\n","\n","    ], additional_targets={'mask': 'mask'})\n","\n","def get_standard_augmentation_pipeline(): # used for up to 3 classes so far\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.3),\n","\n","        # Leichte Rotation/Skalierung, aber nicht zu komplex\n","        A.OneOf([\n","            A.Rotate(limit=10, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n","            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, border_mode=cv2.BORDER_REFLECT_101, p=0.4),\n","            A.NoOp()\n","        ], p=0.6),\n","\n","        # Weniger komplexe Verzerrungen, vielleicht ab und zu GridDistortion, aber mild\n","        A.OneOf([\n","            A.GridDistortion(num_steps=5, distort_limit=0.15, p=0.3),\n","            A.NoOp()\n","        ], p=0.4),\n","\n","        # Beleuchtungsvariationen moderat\n","        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n","\n","        A.RandomGamma(gamma_limit=(80,120), p=0.3),\n","\n","        # Ggf. leichte Sch√§rfe oder Blur\n","        A.OneOf([\n","            A.Blur(blur_limit=3, p=0.3),\n","            A.Sharpen(alpha=(0.2, 0.4), lightness=(0.8,1.0), p=0.3),\n","            A.NoOp()\n","        ], p=0.3),\n","\n","    ], additional_targets={'mask': 'mask'})\n"],"metadata":{"id":"fK807SXCPAF-","executionInfo":{"status":"ok","timestamp":1733837914167,"user_tz":-60,"elapsed":211,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### 2. DataGenerator[Linktext](https://)"],"metadata":{"id":"4SSJdJ5oYyNo"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, images, masks, batch_size, augmentations=None, shuffle=True):\n","        self.images = images\n","        self.masks = masks\n","        self.batch_size = batch_size\n","        self.augment = augmentations\n","        self.shuffle = shuffle\n","        self.indices = np.arange(len(images))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.images) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        batch_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n","        batch_images = self.images[batch_indices]\n","        batch_masks = self.masks[batch_indices]\n","\n","        augmented_images = []\n","        augmented_masks = []\n","\n","        for img, mask in zip(batch_images, batch_masks):\n","            augmented = self.augment(image=img.squeeze(), mask=mask)\n","            aug_img = augmented['image'].astype(np.float32)\n","            aug_mask = augmented['mask'].astype(np.int32)\n","            aug_img = np.expand_dims(aug_img, axis=-1)\n","            augmented_images.append(aug_img)\n","            augmented_masks.append(aug_mask)\n","\n","        return np.array(augmented_images), np.array(augmented_masks)\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            np.random.shuffle(self.indices)\n"],"metadata":{"id":"MwSxxdKFZCVl","executionInfo":{"status":"ok","timestamp":1733837918667,"user_tz":-60,"elapsed":242,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","# Instantiate augmentation pipelines\n","bedrock_augment = AugmentationLogger(get_bedrock_augmentation_pipeline()) # wrap around the Logger if you want to see which augmentations where actually performed\n","min_4_classes_augment = get_3_classes_augmentation_pipeline()\n","standard_augment = get_standard_augmentation_pipeline()\n","\n","# Create training generator with standard augmentations for images with min 4 labels\n","train_generator_min_4 = DataGenerator(\n","    images=x_train_cleaned_min_4_labels_without_bed_rock,\n","    masks=y_train_cleaned_min_4_labels_without_bed_rock,\n","    batch_size=batch_size,\n","    augmentations=min_4_classes_augment,\n","    shuffle=True\n",")\n","\n","# Create training generator with standard augmentations for images with 3 labels\n","train_generator_3 = DataGenerator(\n","    images=x_train_cleaned_3_labels_without_bed_rock,\n","    masks=y_train_cleaned_3_labels_without_bed_rock,\n","    batch_size=batch_size,\n","    augmentations=standard_augment,\n","    shuffle=True\n",")\n","\n","# Create training generator with standard augmentations for images with max 2 labels\n","train_generator_max_2 = DataGenerator(\n","    images=x_train_cleaned_max_2_labels,\n","    masks=y_train_cleaned_max_2_labels,\n","    batch_size=batch_size,\n","    augmentations=standard_augment,\n","    shuffle=True\n",")\n","\n","# Create bedrock generator\n","train_generator_bedrock = DataGenerator(\n","    images=x_bed_rock_selection,\n","    masks=y_bed_rock_selection,\n","    batch_size=batch_size,\n","    augmentations=bedrock_augment,\n","    shuffle=True\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwkplp5gZt38","executionInfo":{"status":"ok","timestamp":1733839395929,"user_tz":-60,"elapsed":218,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"6441f1e2-03d9-4f43-8e0d-f518d7b49beb"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/blur/functional.py:148: UserWarning: blur_limit: Invalid kernel size range (3, 2). Values less than 3 are not allowed. Range automatically adjusted to (3, 3).\n","  result = _ensure_min_value(result, min_value, info.field_name)\n"]}]},{"cell_type":"markdown","source":["### visualize some generated samples (sorry for the duplicate code)"],"metadata":{"id":"ziqBujxfqndO"}},{"cell_type":"code","source":["def visualize_augmented_samples_with_logs(generator, num_samples=5, num_augmented=3):\n","    \"\"\"\n","    Visualize original images/masks, their augmented versions, and the applied augmentations.\n","\n","    Parameters:\n","    - generator: Instance of DataGenerator\n","    - num_samples: Number of original samples to display\n","    - num_augmented: Number of augmented versions per original\n","    \"\"\"\n","    total_rows = num_samples * (1 + num_augmented)\n","\n","    fig, axes = plt.subplots(\n","        nrows=total_rows,\n","        ncols=2,\n","        figsize=(10, total_rows * 2)\n","    )\n","\n","    sample_indices = np.random.choice(len(generator.images), num_samples, replace=False)\n","    sample_images = generator.images[sample_indices]\n","    sample_masks = generator.masks[sample_indices]\n","\n","    row = 0\n","    for i in range(num_samples):\n","        image = sample_images[i].squeeze()\n","        mask = sample_masks[i]\n","\n","        axes[row, 0].imshow(image, cmap='gray')\n","        axes[row, 0].set_title('Original Image')\n","        axes[row, 0].axis('off')\n","\n","        axes[row, 1].imshow(mask, cmap='viridis', vmin=0, vmax=np.max(mask))\n","        axes[row, 1].set_title('Original Mask')\n","        axes[row, 1].axis('off')\n","\n","        row += 1\n","\n","        for j in range(num_augmented):\n","            augmented = generator.augment(image=image, mask=mask) if generator.augment else {'image': image, 'mask': mask}\n","            aug_image = augmented['image']\n","            aug_mask = augmented['mask']\n","\n","            # Log applied augmentations\n","            if isinstance(generator.augment, AugmentationLogger):\n","                aug_logs = generator.augment.get_log()\n","            else:\n","                aug_logs = []\n","\n","            axes[row, 0].imshow(aug_image.squeeze(), cmap='gray')\n","            axes[row, 0].set_title(f'Augmented Image {j + 1}')\n","            axes[row, 0].axis('off')\n","\n","            axes[row, 1].imshow(aug_mask, cmap='viridis', vmin=0, vmax=4)\n","            axes[row, 1].set_title(f'Augmented Mask {j + 1}')\n","            axes[row, 1].axis('off')\n","\n","            # Add the log as text below the augmented image\n","            text = '\\n'.join(aug_logs)\n","            fig.text(0.5, (total_rows - row - 1) / total_rows, text, ha='center', fontsize=8)\n","\n","            row += 1\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def visualize_augmented_samples(generator, num_samples=5, num_augmented=3):\n","    \"\"\"\n","    Visualize original images/masks and their augmented versions.\n","\n","    Parameters:\n","    - generator: Instance of DataGenerator\n","    - num_samples: Number of original samples to display\n","    - num_augmented: Number of augmented versions per original\n","    \"\"\"\n","    # Calculate the total number of rows needed\n","    total_rows = num_samples * (1 + num_augmented)\n","\n","    # Set the figure size dynamically based on the number of rows and columns\n","    fig, axes = plt.subplots(\n","        nrows=total_rows,\n","        ncols=2,\n","        figsize=(8, total_rows * 2)\n","    )\n","\n","    # Select random samples from the generator\n","    sample_indices = np.random.choice(len(generator.images), num_samples, replace=False)\n","    sample_images = generator.images[sample_indices]\n","    sample_masks = generator.masks[sample_indices]\n","\n","    row = 0\n","    for i in range(num_samples):\n","        image = sample_images[i].squeeze()\n","        mask = sample_masks[i]\n","\n","        # Display Original Image\n","        axes[row, 0].imshow(image, cmap='gray')\n","        axes[row, 0].set_title('Original Image')\n","        axes[row, 0].axis('off')\n","\n","        # Display Original Mask\n","        axes[row, 1].imshow(mask, cmap=custom_cmap, vmin=0, vmax=4)  # Replace 'viridis' if custom cmap\n","        axes[row, 1].set_title('Original Mask')\n","        axes[row, 1].axis('off')\n","\n","        row += 1\n","\n","        # Generate and display augmented samples\n","        for j in range(num_augmented):\n","            augmented = generator.augment(image=image, mask=mask) if generator.augment else {'image': image, 'mask': mask}\n","            aug_image = augmented['image']\n","            aug_mask = augmented['mask']\n","\n","            # Augmented Image\n","            axes[row, 0].imshow(aug_image.squeeze(), cmap='gray')\n","            axes[row, 0].set_title(f'Augmented Image {j + 1}')\n","            axes[row, 0].axis('off')\n","\n","            # Augmented Mask\n","            axes[row, 1].imshow(aug_mask, cmap=custom_cmap, vmin=0, vmax=4)  # Replace 'viridis' if custom cmap\n","            axes[row, 1].set_title(f'Augmented Mask {j + 1}')\n","            axes[row, 1].axis('off')\n","\n","            row += 1\n","\n","    # Adjust layout for better visualization\n","    plt.tight_layout()\n","    plt.show()\n","\n"],"metadata":{"id":"WJCRYRw93Sav","executionInfo":{"status":"ok","timestamp":1733839711934,"user_tz":-60,"elapsed":230,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["### choose visualization with or without logs"],"metadata":{"id":"josdVO7M5arr"}},{"cell_type":"code","source":["# Visualize augmentations for images with min 4 labels\n","visualize_augmented_samples(train_generator_min_4, num_samples=5, num_augmented=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"k0VKvXRtqvn-","executionInfo":{"status":"error","timestamp":1733839653273,"user_tz":-60,"elapsed":2365,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"6497330e-0e38-4288-a754-077a05588f3a"},"execution_count":52,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-24cd992382ef>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize augmentations for images with min 4 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_augmented_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator_min_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_augmented\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-25fb0c1ffa17>\u001b[0m in \u001b[0;36mvisualize_augmented_samples\u001b[0;34m(generator, num_samples, num_augmented)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Adjust layout for better visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \"\"\"\n\u001b[1;32m    526\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2185\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2187\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2188\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2042\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2044\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \"\"\"\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    443\u001b[0m         *pil_kwargs* and *metadata* are forwarded).\n\u001b[1;32m    444\u001b[0m         \"\"\"\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    447\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         with (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    387\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m                 mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3155\u001b[0m                     renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3032\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2976\u001b[0m                 \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2978\u001b[0;31m                     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update offsetText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2979\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2612\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 \u001b[0mspine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2614\u001b[0;31m                 \u001b[0mspinebbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2615\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2616\u001b[0m                 \u001b[0;31m# use Axes if spine doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/spines.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mdrawn_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mmajor_tick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdrawn_ticks\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \"\"\"\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;34m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2149\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2088\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   2089\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   2090\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tick_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2758\u001b[0;31m         ends = mtransforms.Bbox.unit().transformed(\n\u001b[0m\u001b[1;32m   2759\u001b[0m             self.axes.transAxes - self.figure.dpi_scale_trans)\n\u001b[1;32m   2760\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36munit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;34m\"\"\"Create a new unit `Bbox` from (0, 0) to (1, 1).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, points, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \"\"\"\n\u001b[1;32m    765\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise ValueError('Bbox points must be of the form '\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Visualize augmentations for images with 3 classes\n","visualize_augmented_samples(train_generator_3, num_samples=3, num_augmented=3)"],"metadata":{"id":"OzPzG3y3xDrk","executionInfo":{"status":"aborted","timestamp":1733839653274,"user_tz":-60,"elapsed":4,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize augmentations for images with max 2 classes\n","visualize_augmented_samples(train_generator_max_2, num_samples=3, num_augmented=3)"],"metadata":{"id":"AVe80xaLxQQH","executionInfo":{"status":"aborted","timestamp":1733839653274,"user_tz":-60,"elapsed":4,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Visualize augmentations for bedrock images\n","visualize_augmented_samples_with_logs(train_generator_bedrock, num_samples=3, num_augmented=3)"],"metadata":{"id":"SBj2KAQjxaHg","executionInfo":{"status":"aborted","timestamp":1733839653274,"user_tz":-60,"elapsed":3,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Upsample through Augmentation, if we're happy with the pipeline"],"metadata":{"id":"PFlAAjc55_4f"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import numpy as np\n","\n","def augment_images(images, masks, augmentation_pipeline, augment_times):\n","    \"\"\"\n","    Apply augmentation_pipeline to each image-mask pair augment_times times.\n","    Displays progress using tqdm.\n","\n","    Parameters:\n","    - images: NumPy array of images (N, H, W, C) where C=1 for grayscale\n","    - masks: NumPy array of masks (N, H, W)\n","    - augmentation_pipeline: Albumentations augmentation pipeline\n","    - augment_times: Number of augmented copies per image\n","\n","    Returns:\n","    - augmented_images: Augmented images as NumPy array (N', H, W, C)\n","    - augmented_masks: Augmented masks as NumPy array (N', H, W)\n","    \"\"\"\n","    augmented_images = []\n","    augmented_masks = []\n","\n","    # Initialize tqdm progress bar\n","    total_augmentations = len(images) * augment_times\n","    with tqdm(total=total_augmentations, desc=\"Augmenting Images and Masks\") as pbar:\n","        for img, mask in zip(images, masks):\n","            for _ in range(augment_times):\n","                # Albumentations expects images as (H, W, C) and masks as (H, W)\n","                augmented = augmentation_pipeline(image=img.squeeze(), mask=mask)\n","                aug_img = augmented['image'].astype(np.float32)  # Ensure image dtype\n","                aug_mask = augmented['mask'].astype(np.int32)    # Ensure mask dtype\n","\n","                # Add channel dimension back to image (grayscale)\n","                aug_img = np.expand_dims(aug_img, axis=-1)\n","\n","                augmented_images.append(aug_img)\n","                augmented_masks.append(aug_mask)\n","\n","                # Update progress bar\n","                pbar.update(1)\n","\n","    # Convert lists to NumPy arrays\n","    return np.array(augmented_images), np.array(augmented_masks)"],"metadata":{"id":"amobB6RY6wpb","executionInfo":{"status":"ok","timestamp":1733840065971,"user_tz":-60,"elapsed":264,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# How to use\n","x_bed_rock_selection_augmented, y_bed_rock_selection_augmented = augment_images(\n","    x_bed_rock_selection,\n","    y_bed_rock_selection,\n","    bedrock_augment,\n","    augment_times=3\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bdr5R5hk65IC","executionInfo":{"status":"ok","timestamp":1733840154739,"user_tz":-60,"elapsed":264,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"39213b4c-8029-41f5-c5b9-f6a6aecc9d2b"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["Augmenting Images and Masks: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 837.88it/s]\n"]}]},{"cell_type":"markdown","source":["## Model stuff"],"metadata":{"id":"nHcr9AEkcHZI"}},{"cell_type":"code","source":["inputs = tfkl.Input(shape=input_shape)\n","x = tfkl.Conv2D(filters=num_classes, kernel_size=(1, 1), activation=\"softmax\")(inputs)\n","model = tfk.Model(inputs=inputs, outputs=x, name=\"minimal_working_net\")\n","\n","# Define the MeanIoU ignoring the background class\n","mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False)\n","\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[mean_iou])\n","\n","model.summary()"],"metadata":{"id":"CBkb3TRF1KJx","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1733779210806,"user_tz":-60,"elapsed":321,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"72a67bd2-c97e-49a5-f10e-ae2678cc35ca"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"minimal_working_net\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"minimal_working_net\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m5\u001b[0m)          ‚îÇ              \u001b[38;5;34m10\u001b[0m ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Use loaded data in your model"],"metadata":{"id":"wLhm6i4r6RK6"}},{"cell_type":"code","source":["# Fit the model\n","history = model.fit(\n","    # on augmented data\n","    train_data=(X_train_augmented, y_train_augmented),\n","    # or on cleaned data:\n","    # train_data=(x_train_cleaned, y_train_cleaned),\n","    validation_data=(x_val, y_val),\n","    epochs=10,\n","    batch_size=64,\n",")"],"metadata":{"id":"vjXyoSv_41Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tfkl.Input(shape=input_shape)\n","x = tfkl.Conv2D(filters=num_classes, kernel_size=(1, 1), activation=\"softmax\")(inputs)\n","model = tfk.Model(inputs=inputs, outputs=x, name=\"minimal_working_net\")\n","\n","# Define the MeanIoU ignoring the background class\n","mean_iou = tfk.metrics.MeanIoU(num_classes=num_classes, ignore_class=0, sparse_y_pred=False)\n","\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[mean_iou])\n","\n","model.summary()\n","\n","history = model.fit(X_train, y_train, epochs=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"1XU7k5IWTEmb","executionInfo":{"status":"ok","timestamp":1733779330506,"user_tz":-60,"elapsed":19360,"user":{"displayName":"Theresa Laura","userId":"11139758655606804957"}},"outputId":"3fb2f163-dded-4274-e5c8-c0dcea0f03f7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"minimal_working_net\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"minimal_working_net\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)          ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m5\u001b[0m)          ‚îÇ              \u001b[38;5;34m10\u001b[0m ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n","‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n","‚îÇ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)          ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> ‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","\u001b[1m82/82\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - loss: 1.6226 - mean_io_u_2: 0.0918\n","Epoch 2/2\n","\u001b[1m82/82\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - loss: 1.5858 - mean_io_u_2: 0.1144\n"]}]},{"cell_type":"markdown","source":["## Function to evaluate the model and visualize predictions"],"metadata":{"id":"FxIYHSn5G9Hn"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import tensorflow as tf\n","\n","def evaluate_model_performance(model, X_test, y_test, class_names):\n","    \"\"\"\n","    Evaluates the performance of a segmentation model on the test set.\n","\n","    Args:\n","        model: Trained segmentation model.\n","        X_test: Test images, shape (num_samples, height, width, channels).\n","        y_test: Ground truth masks, shape (num_samples, height, width).\n","        class_names: List of class names (e.g., [\"background\", \"rock\", \"sand\", \"crater\", \"other\"]).\n","\n","    Returns:\n","        Prints and plots detailed metrics, including IoU per class, accuracy, and a combined confusion matrix.\n","    \"\"\"\n","    # Predict masks for the test set\n","    y_pred = model.predict(X_test, batch_size=16)\n","    y_pred_classes = np.argmax(y_pred, axis=-1)  # Convert to class indices\n","\n","    # Flatten the arrays for confusion matrix computation\n","    y_test_flat = y_test.flatten()\n","    y_pred_flat = y_pred_classes.flatten()\n","\n","    # Compute the confusion matrix\n","    combined_cm = confusion_matrix(y_test_flat, y_pred_flat, labels=np.arange(len(class_names)))\n","\n","    # Normalize the confusion matrix\n","    combined_cm_normalized = combined_cm.astype('float') / combined_cm.sum(axis=1)[:, np.newaxis]\n","\n","    # Calculate IoU for each class\n","    num_classes = len(class_names)\n","    iou_per_class = []\n","    for c in range(num_classes):\n","        intersection = combined_cm[c, c]\n","        union = combined_cm[c, :].sum() + combined_cm[:, c].sum() - intersection\n","        iou = intersection / union if union > 0 else 0\n","        iou_per_class.append(iou)\n","\n","    # Overall metrics\n","    mean_iou = np.mean(iou_per_class)\n","    pixel_accuracy = np.sum(y_pred_flat == y_test_flat) / len(y_test_flat)\n","\n","    # Print metrics\n","    print(\"Evaluation Results:\")\n","    print(\"-------------------\")\n","    print(f\"Pixel-wise Accuracy: {pixel_accuracy:.4f}\")\n","    print(f\"Mean IoU: {mean_iou:.4f}\")\n","    print(\"\\nClass-wise IoU:\")\n","    for i, class_name in enumerate(class_names):\n","        print(f\"  {class_name}: {iou_per_class[i]:.4f}\")\n","\n","    # Plot the combined confusion matrix\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(combined_cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n","    plt.title(\"Normalized Confusion Matrix\")\n","    plt.xlabel(\"Predicted Class\")\n","    plt.ylabel(\"True Class\")\n","    plt.show()\n","\n","    # Visualize some predictions\n","    def visualize_predictions(X, y_true, y_pred, num_samples=5):\n","        indices = np.random.choice(len(X), num_samples, replace=False)\n","        for idx in indices:\n","            plt.figure(figsize=(12, 6))\n","            plt.subplot(1, 3, 1)\n","            plt.title(\"Input Image\")\n","            plt.imshow(X[idx].squeeze(), cmap=\"gray\")\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 3, 2)\n","            plt.title(\"Ground Truth\")\n","            plt.imshow(y_true[idx], cmap=\"viridis\", vmin=0, vmax=num_classes - 1)\n","            plt.axis(\"off\")\n","\n","            plt.subplot(1, 3, 3)\n","            plt.title(\"Predicted Mask\")\n","            plt.imshow(y_pred[idx], cmap=\"viridis\", vmin=0, vmax=num_classes - 1)\n","            plt.axis(\"off\")\n","\n","            plt.show()\n","\n","    print(\"\\nSample Predictions:\")\n","    visualize_predictions(X_test, y_test, y_pred_classes)\n"],"metadata":{"id":"n3cFLibEHCdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# How to use:\n","class_names = [\"background\", \"soil\", \"bedrock\", \"sand\", \"bigrock\"]\n","evaluate_model_performance(model, x_val, y_val, class_names)"],"metadata":{"id":"1ZlMKl85HD0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","def visualize_test_predictions(model, test_set, num_imgs, custom_cmap=None):\n","    \"\"\"\n","    Visualizes random predictions from the test set with predicted masks overlayed.\n","\n","    Args:\n","        model: Trained segmentation model.\n","        test_set: Test images, shape (num_samples, height, width, channels).\n","        num_imgs: Number of random test images to visualize.\n","        custom_cmap: (Optional) A colormap for visualizing masks.\n","                     Default uses `plt.cm.viridis`.\n","\n","    Returns:\n","        Displays the input images with predicted masks overlayed.\n","    \"\"\"\n","    # Generate predictions\n","    predictions = model.predict(test_set, batch_size=16)\n","    predicted_masks = np.argmax(predictions, axis=-1)  # Convert logits to class indices\n","\n","    # Randomly select images to visualize\n","    indices = np.random.choice(len(test_set), num_imgs, replace=False)\n","\n","    for idx in indices:\n","        plt.figure(figsize=(12, 6))\n","\n","        # Input image\n","        plt.subplot(1, 2, 1)\n","        plt.title(\"Input Image\")\n","        plt.imshow(test_set[idx].squeeze(), cmap=\"gray\")  # Grayscale display\n","        plt.axis(\"off\")\n","\n","        # Predicted mask overlayed\n","        plt.subplot(1, 2, 2)\n","        plt.title(\"Predicted Mask Overlayed\")\n","        plt.imshow(test_set[idx].squeeze(), cmap=\"gray\",  alpha=0.8)  # Original image\n","        plt.imshow(predicted_masks[idx], cmap=custom_cmap or \"viridis\",vmin=0, vmax=4, alpha=0.5)  # Overlay mask\n","        plt.axis(\"off\")\n","\n","        plt.show()\n"],"metadata":{"id":"G_WkuDpiRumy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n","model_filename = f\"model_{timestep_str}.keras\"\n","model.save(model_filename)\n","del model\n","\n","print(f\"Model saved to {model_filename}\")"],"metadata":{"id":"PtM0ubgdOzG-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üìä Prepare Your Submission\n","\n","In our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n","\n","\n"],"metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":["# If model_filename is not defined, load the most recent model from Google Drive\n","if \"model_filename\" not in globals() or model_filename is None:\n","    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n","    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n","    if files:\n","        model_filename = files[0]\n","    else:\n","        raise FileNotFoundError(\"No model files found in the current directory.\")"],"metadata":{"id":"BU00iEFcYi_X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XkMNK3f7G7n2"}},{"cell_type":"code","source":[],"metadata":{"id":"PtYiMmulG6hB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tfk.models.load_model(model_filename)\n","print(f\"Model loaded from {model_filename}\")"],"metadata":{"id":"FMIq69eWgRmr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = model.predict(X_test)\n","preds = np.argmax(preds, axis=-1)\n","print(f\"Predictions shape: {preds.shape}\")"],"metadata":{"id":"z287uIQ_VGoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def y_to_df(y) -> pd.DataFrame:\n","    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n","    n_samples = len(y)\n","    y_flat = y.reshape(n_samples, -1)\n","    df = pd.DataFrame(y_flat)\n","    df[\"id\"] = np.arange(n_samples)\n","    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n","    return df[cols]"],"metadata":{"id":"SPjMEKqZW5jX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create and download the csv submission file\n","timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n","submission_filename = f\"submission_{timestep_str}.csv\"\n","submission_df = y_to_df(preds)\n","submission_df.to_csv(submission_filename, index=False)\n","\n","from google.colab import files\n","files.download(submission_filename)"],"metadata":{"id":"s18kX1uDconq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  \n","<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n","___\n","Credits: Alberto Archetti üìß alberto.archetti@polito.it\n","\n","\n","\n","\n","\n","```\n","   Copyright 2024 Alberto Archetti\n","\n","   Licensed under the Apache License, Version 2.0 (the \"License\");\n","   you may not use this file except in compliance with the License.\n","   You may obtain a copy of the License at\n","\n","       http://www.apache.org/licenses/LICENSE-2.0\n","\n","   Unless required by applicable law or agreed to in writing, software\n","   distributed under the License is distributed on an \"AS IS\" BASIS,\n","   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","   See the License for the specific language governing permissions and\n","   limitations under the License.\n","```"],"metadata":{"id":"cQEgmFTPfz1n"}}]}